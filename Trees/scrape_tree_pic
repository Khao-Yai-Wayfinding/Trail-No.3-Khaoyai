import requests
from bs4 import BeautifulSoup
import json
import re

URL = "https://khaoyainationalpark.com/en/discover/flora"
res = requests.get(URL)
soup = BeautifulSoup(res.text, "html.parser")

# Find all headers (skip the first "Flora" header)
headings = soup.select("h3, h2")[1:]

nodes = []
for h in headings:
    title = h.get_text(strip=True)

    desc = []
    image_url = None

    for sib in h.next_siblings:
        if sib.name in ["h2", "h3"]:
            break
        if sib.name == "p":
            desc.append(sib.get_text(strip=True))
        if sib.name == "figure":
            img_tag = sib.find("img")
            if img_tag and img_tag.has_attr("src"):
                image_url = img_tag["src"]
                # make full URL if needed
                if image_url.startswith("/"):
                    image_url = "https://khaoyainationalpark.com" + image_url

    full_desc = " ".join(desc)

    sci = None
    m = re.search(r"([A-Z][a-z]+ [a-z]+)", full_desc)
    if m:
        sci = m.group(1)

    season = None
    if re.search(r"hot season|dry season|May|June|February|April", full_desc, re.I):
        season = "Season-clue-present"

    nodes.append({
        "id": title.replace(" ", "_"),
        "name": title,
        "scientific": sci or "",
        "season_note": season or "",
        "image": image_url or "",
        "type": "",  # to fill manually
        "size": ""   # to fill manually
    })

# Output JSON
print(json.dumps({"nodes": nodes, "links": []}, indent=2))
